{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Input, Dropout, UpSampling2D\n",
    "from keras.layers import Flatten, BatchNormalization, Dense, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General constants \n",
    "# Shape of the dataset and generator output images.\n",
    "image_shape = (64, 64, 3)\n",
    "\n",
    "# Dataset batch size\n",
    "batch_size = 100\n",
    "\n",
    "# Number of channels of the dataset and generator output images.\n",
    "# n_channels = 3\n",
    "\n",
    "# How many epochs should train last.\n",
    "epochs = 16000\n",
    "\n",
    "## Dataset related constants \n",
    "#  Dataset path\n",
    "dataset_path = \"./logos_dataset/class/\"\n",
    "\n",
    "latent_dimensions = 100\n",
    "\n",
    "display_interval = 20\n",
    "\n",
    "# # Last epoch during previous training (in case training\n",
    "# # has continued from the checkpoint).\n",
    "# last_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining load_dataset function\n",
    "def load_dataset(dataset_path, batch_size, image_shape):\n",
    "    dataset_generator = ImageDataGenerator()\n",
    "    dataset_generator = dataset_generator.flow_from_directory(\n",
    "        dataset_path, target_size=(image_shape[0], image_shape[1]),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None)\n",
    "    \n",
    "    return dataset_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the generator model. \n",
    "def generator_model():\n",
    "    generator = Sequential()\n",
    "\n",
    "    generator.add(Dense(units=4 * 4 * 512,\n",
    "                        kernel_initializer='glorot_uniform',\n",
    "                        input_shape=(1, 1, 100)))\n",
    "    generator.add(Reshape(target_shape=(4, 4, 512)))\n",
    "    generator.add(BatchNormalization(momentum=0.5))\n",
    "    generator.add(Activation('relu'))\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
    "                                  strides=(2, 2), padding='same',\n",
    "                                  data_format='channels_last',\n",
    "                                  kernel_initializer='glorot_uniform'))\n",
    "    generator.add(BatchNormalization(momentum=0.5))\n",
    "    generator.add(Activation('relu'))\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
    "                                  strides=(2, 2), padding='same',\n",
    "                                  data_format='channels_last',\n",
    "                                  kernel_initializer='glorot_uniform'))\n",
    "    generator.add(BatchNormalization(momentum=0.5))\n",
    "    generator.add(Activation('relu'))\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
    "                                  strides=(2, 2), padding='same',\n",
    "                                  data_format='channels_last',\n",
    "                                  kernel_initializer='glorot_uniform'))\n",
    "    generator.add(BatchNormalization(momentum=0.5))\n",
    "    generator.add(Activation('relu'))\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
    "                                  strides=(2, 2), padding='same',\n",
    "                                  data_format='channels_last',\n",
    "                                  kernel_initializer='glorot_uniform'))\n",
    "    generator.add(Activation('tanh'))\n",
    "\n",
    "    optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
    "    generator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=None)\n",
    "\n",
    "    print('generator')\n",
    "    generator.summary()\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the discriminator model. \n",
    "def discriminator_model(image_shape):\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Conv2D(filters=64, kernel_size=(5, 5),\n",
    "                             strides=(2, 2), padding='same',\n",
    "                             data_format='channels_last',\n",
    "                             kernel_initializer='glorot_uniform',\n",
    "                             input_shape=(image_shape)))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Conv2D(filters=128, kernel_size=(5, 5),\n",
    "                             strides=(2, 2), padding='same',\n",
    "                             data_format='channels_last',\n",
    "                             kernel_initializer='glorot_uniform'))\n",
    "    discriminator.add(BatchNormalization(momentum=0.5))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Conv2D(filters=256, kernel_size=(5, 5),\n",
    "                             strides=(2, 2), padding='same',\n",
    "                             data_format='channels_last',\n",
    "                             kernel_initializer='glorot_uniform'))\n",
    "    discriminator.add(BatchNormalization(momentum=0.5))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Conv2D(filters=512, kernel_size=(5, 5),\n",
    "                             strides=(2, 2), padding='same',\n",
    "                             data_format='channels_last',\n",
    "                             kernel_initializer='glorot_uniform'))\n",
    "    discriminator.add(BatchNormalization(momentum=0.5))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1))\n",
    "    discriminator.add(Activation('sigmoid'))\n",
    "\n",
    "    optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "    discriminator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=None)\n",
    "\n",
    "    print('discriminator')\n",
    "    discriminator.summary()\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying and saving generated images as '.png' \n",
    "def save_generated_images(generated_images, epoch, batch_number):\n",
    "    plt.figure(figsize=(8, 8), num=2)\n",
    "    gs1 = gridspec.GridSpec(8, 8)\n",
    "    gs1.update(wspace=0, hspace=0)\n",
    "\n",
    "    for i in range(64):\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        ax1.set_aspect('equal')\n",
    "        image = generated_images[i, :, :, :]\n",
    "        image += 1\n",
    "        image *= 127.5\n",
    "        fig = plt.imshow(image.astype(np.uint8))\n",
    "        plt.axis('off')\n",
    "        fig.axes.get_xaxis().set_visible(False)\n",
    "        fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_name = 'generated images/generatedSamples_epoch' + str(\n",
    "        epoch + 1) + '_batch' + str(batch_number + 1) + '.png'\n",
    "\n",
    "    plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
    "    plt.pause(0.0000000001)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building adversarial model(gan)\n",
    "def train_dcgan(batch_size, epochs, image_shape, dataset_path):\n",
    "    generator = construct_generator()\n",
    "    discriminator = construct_discriminator(image_shape)\n",
    "\n",
    "    gan = Sequential()\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "\n",
    "    if os.path.exists(\"./output/generator_weights.h5\"):\n",
    "        print('loaded generator model weights')\n",
    "        generator.load_weights('./output/generator_weights.h5')\n",
    "\n",
    "    if os.path.exists(\"./output/discriminator_weights.h5\"):\n",
    "        print('loaded discriminator model weights')\n",
    "        discriminator.load_weights('./output/discriminator_weights.h5')\n",
    "\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.5)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                metrics=None)\n",
    "\n",
    "    # Creating a dataset Generator \n",
    "    dataset_generator = load_dataset(dataset_path, batch_size, image_shape)\n",
    "\n",
    "    # Total number of images used is 1073\n",
    "    number_of_batches = int(1073 / batch_size)\n",
    "\n",
    "    # Variables that will be used to plot the losses from the discriminator and\n",
    "    # the adversarial models\n",
    "    adversarial_loss = np.empty(shape=1)\n",
    "    discriminator_loss = np.empty(shape=1)\n",
    "    batches = np.empty(shape=1)\n",
    "\n",
    "    # plot updates inside for loop\n",
    "    plt.ion()\n",
    "\n",
    "    current_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting current_batch to 1\n",
    "current_batch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining generator loss function\n",
    "def gen_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dicriminator loss function\n",
    "def disc_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Creating dataset generator \n",
    "dataset_generator = load_dataset(dataset_path, batch_size, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of images used is 1073\n",
    "number_of_batches = int(1073 / batch_size)\n",
    "\n",
    "# Variables that will be used to plot the losses from the discriminator and\n",
    "# the adversarial models\n",
    "adversarial_loss = np.empty(shape=1)\n",
    "discriminator_loss = np.empty(shape=1)\n",
    "batches = np.empty(shape=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating generator\n",
    "generator = generator_model()\n",
    "\n",
    "# creating discriminator\n",
    "discriminator = discriminator_model(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating gan model\n",
    "gan = Sequential()\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan.add(generator)\n",
    "gan.add(discriminator)\n",
    "\n",
    "optimizer = Adam(lr=0.00015, beta_1=0.5)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "            metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a utility function to display the generated images\n",
    "\n",
    "def display_images():\n",
    "    r,c = 4,4\n",
    "    noise = np.random.normal(0, 1, size=(current_batch_size,) + (1, 1, 100))\n",
    "    generated_images = generator.predict(noise)\n",
    "    \n",
    "    #Scaling the generated images\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    \n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    count = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(generated_images[count, :,:,])\n",
    "            axs[i,j].axis('off')\n",
    "            count +=1\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training DcGAN for n epochs\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch \" + str(epoch+1) + \"/\" + str(epochs) + \" :\")\n",
    "    \n",
    "    for batch_number in range(number_of_batches):\n",
    "        start_time = time.time()\n",
    "        # Get the current batch and normalize the images between -1 and 1\n",
    "        real_images = dataset_generator.next()\n",
    "        real_images /= 127.5\n",
    "        real_images -= 1\n",
    "\n",
    "        # The last batch is smaller than the other ones, so we need to\n",
    "        # take that into account\n",
    "        current_batch_size = real_images.shape[0]\n",
    "\n",
    "        # Generate noise\n",
    "        noise = np.random.normal(0, 1,\n",
    "                                size=(current_batch_size,) + (1, 1, 100))\n",
    "\n",
    "        # Generate images\n",
    "        generated_images = generator.predict(noise)\n",
    "\n",
    "        # Add some noise to the labels that will be\n",
    "        # fed to the discriminator\n",
    "        real_output = (np.ones(current_batch_size) -\n",
    "                      np.random.random_sample(current_batch_size) * 0.2)\n",
    "        fake_output = np.random.random_sample(current_batch_size) * 0.2\n",
    "\n",
    "        # Let's train the discriminator\n",
    "        discriminator.trainable = True\n",
    "\n",
    "        d_loss = discriminator.train_on_batch(real_images, real_output)\n",
    "        d_loss += discriminator.train_on_batch(generated_images, fake_output)\n",
    "\n",
    "        discriminator_loss = np.append(discriminator_loss, d_loss)\n",
    "\n",
    "        # Now it's time to train the generator\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        noise = np.random.normal(0, 1,\n",
    "                                size=(current_batch_size * 2,) +\n",
    "                                (1, 1, 100))\n",
    "\n",
    "        # We try to mislead the discriminator by giving the opposite labels\n",
    "        fake_output = (np.ones(current_batch_size * 2) -\n",
    "                  np.random.random_sample(current_batch_size * 2) * 0.2)\n",
    "\n",
    "        g_loss = gan.train_on_batch(noise, fake_output)\n",
    "        adversarial_loss = np.append(adversarial_loss, g_loss)\n",
    "        batches = np.append(batches, current_batch)\n",
    "\n",
    "        # Each 5 batches show and save images\n",
    "        if((batch_number + 1) % 5 == 0 and\n",
    "            current_batch_size == batch_size):\n",
    "            save_generated_images(generated_images, epoch, batch_number)\n",
    "\n",
    "        time_elapsed = time.time() - start_time\n",
    "\n",
    "        # Display and plot the results\n",
    "        print(\"     Batch \" + str(batch_number + 1) + \"/\" +\n",
    "             str(number_of_batches) +\n",
    "             \" generator loss | discriminator loss : \" +\n",
    "             str(g_loss) + \" | \" + str(d_loss) + ' - batch took ' +\n",
    "             str(time_elapsed) + ' s.')\n",
    "\n",
    "        current_batch += 1\n",
    "\n",
    "    # Save the model weights each 4 epochs\n",
    "    if (epoch + 1) % 4 == 0:\n",
    "        discriminator.trainable = True\n",
    "        generator.save('output/generator_epoch' + str(epoch) + '.hdf5')\n",
    "        discriminator.save('output/discriminator_epoch' +\n",
    "                            str(epoch) + '.hdf5')\n",
    "        display_images()\n",
    "        \n",
    "    # Each epoch update the loss graphs\n",
    "    plt.figure(1)\n",
    "    plt.plot(batches, adversarial_loss, color='green',\n",
    "            label='Generator Loss')\n",
    "    plt.plot(batches, discriminator_loss, color='blue',\n",
    "            label='Discriminator Loss')\n",
    "    plt.title(\"DCGAN Train\")\n",
    "    plt.xlabel(\"Batch Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    if epoch == 0:\n",
    "        plt.legend()\n",
    "    plt.pause(0.0000000001)\n",
    "    plt.show()\n",
    "    plt.savefig('trainingLossPlot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset_path = \"./dataset/class/\"\n",
    "    batch_size = 100\n",
    "    image_shape = (64, 64, 3)\n",
    "    epochs = 16000\n",
    "    train_dcgan(batch_size, epochs,\n",
    "                image_shape, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
